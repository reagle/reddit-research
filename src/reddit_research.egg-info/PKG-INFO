Metadata-Version: 2.4
Name: reddit_research
Version: 1.1.0
Summary: Tools for scraping and analyzing Reddit
Author: Joseph Reagle
License: MIT
Requires-Python: >=3.11
Description-Content-Type: text/markdown
Requires-Dist: adjusttext>=1.2.0
Requires-Dist: arrow>=1.3.0
Requires-Dist: cachier>=3.0.1
Requires-Dist: fuzz>=0.1.1
Requires-Dist: jsonlines>=4.0.0
Requires-Dist: lxml>=5.3.0
Requires-Dist: matplotlib>=3.9.2
Requires-Dist: numpy>=2.1.2
Requires-Dist: pandas>=2.2.3
Requires-Dist: pendulum>=3.0.0
Requires-Dist: praw>=7.7.1
Requires-Dist: psaw>=0.1.0
Requires-Dist: pyarrow>=17.0.0
Requires-Dist: pytz>=2024.2
Requires-Dist: python-dotenv>=1.0.0
Requires-Dist: rapidfuzz>=3.11.0
Requires-Dist: requests>=2.32.3
Requires-Dist: seaborn>=0.13.2
Requires-Dist: tabulate>=0.9.0
Requires-Dist: tqdm>=4.66.5
Requires-Dist: zstandard>=0.23.0
Requires-Dist: pip>=24.3.1
Requires-Dist: ipython>=8.31.0
Requires-Dist: sh>=2.1.0
Requires-Dist: ipdb>=0.13.13

Tools for scraping and analyzing Reddit and for messaging Redditors.

```
uv tool install https://github.com/reagle/reddit-research.git
```

Note that the following install is pinned to pendulum 2.1.2 ([pendulum 3 requires rust and cargo](https://pendulum.eustace.io/blog/announcing-pendulum-3-0-0.html)) because wheels are not provided for python 3.13.

## reddit-search

```
â¯ reddit-search -h
usage: reddit-search [-h] [-r] [-c COLUMN] [-L] [-V] [--version] FILE

Facilitate a search of phrases appearing in a spreadsheet column
(default: 'phrase') by generating queries against search engines and
opening the results in browser tabs. Search engines include Google,
Reddit, and RedditSearch/Pushshift.

> reddit-search demo-phrases.csv -c phrase

If you wish to test the efficacy of a disguised/spun phrase, also
include a column of the spun phrase and the 'url' of the source. This
will automatically check the results for that URL.

> reddit-search demo-phrases.csv -c weakspins

positional arguments:
  FILE

options:
  -h, --help           show this help message and exit
  -r, --recheck        recheck non-NULL values in 'found' column
  -c, --column COLUMN  sheet column to query [default: 'phrase']
  -L, --log-to-file    log to file reddit-search.log
  -V, --verbose        increase verbosity from critical though error, warning, info, and debug
  --version            show program's version number and exit
```

## reddit-query

```
usage: reddit-query [-h] [-a AFTER] [-b BEFORE] [-l LIMIT] [-c COMMENTS_NUM]
                    [-r SUBREDDIT] [--sample] [--skip] [-t] [-L] [-V]
                    [--version]

Query Pushshift and Reddit APIs.

options:
  -h, --help            show this help message and exit
  -a, --after AFTER     submissions after: Y-m-d (any pendulum parsable).
                        Using it without before starts in 1970!
  -b, --before BEFORE   submissions before: Y-m-d (any pendulum parsable).
                        Using it without before starts in 1970!
  -l, --limit LIMIT     limit to (default: 5) results
  -c, --comments_num COMMENTS_NUM
                        number of comments threshold '[<>]\d+]' (default:
                        False). Note: this is updated as Pushshift ingests,
                        `score` is not.
  -r, --subreddit SUBREDDIT
                        subreddit to query (default: AmItheAsshole)
  --sample              sample complete date range up to limit, rather than
                        first submissions within limit
  --skip                skip all Reddit fetches; pushshift only
  -t, --throwaway-only  only throwaway accounts ('throw' and 'away') get
                        fetched from Reddit
  -L, --log-to-file     log to file reddit-query.log
  -V, --verbose         increase verbosity from critical though error,
                        warning, info, and debug
  --version             show program's version number and exit
```

## reddit-watch

```
usage: reddit-watch [-h] [-i INIT] [--hours HOURS] [-L] [-V] [--version]

Watch the deletion/removal status of Reddit messages. Initialize subreddits to
be watched first (e.g., 'Advice+AmItheAsshole). Schedule using cron or launchd

options:
  -h, --help         show this help message and exit
  -i, --init INIT    INITIALIZE `+` delimited subreddits to watch
  --hours HOURS      previous HOURS to fetch
  -L, --log-to-file  log to file reddit-watch.log
  -V, --verbose      increase verbosity from critical though error, warning,
                     info, and debug
  --version          show program's version number and exit
```

## reddit-message

```
usage: reddit-message [-h] -i FILENAME [-a FILENAME] [-g FILENAME] [-d] [-e]
                      [-p] [-t] [-r RATE_LIMIT] [-s] [-D] [-L] [-V]
                      [--version]

Message Redditors using CSV files with usernames in column `author_p`. Can
take output of reddit-query or reddit-watch and select users for messaging
based on attributes.

options:
  -h, --help            show this help message and exit
  -i, --input-fn FILENAME
                        CSV filename, with usernames, created by reddit-query
  -a, --archive-fn FILENAME
                        CSV filename of previously messaged users to skip;
                        created if doesn't exist (default: reddit-message-
                        users-past.csv)
  -g, --greeting-fn FILENAME
                        greeting message filename (default: greeting.txt)
  -d, --only-deleted    select deleted users only
  -e, --only-existent   select existent (NOT deleted) users only
  -p, --only-pseudonym  select pseudonyms only (NOT throwaway)
  -t, --only-throwaway  select throwaway accounts only ('throw' and 'away')
  -r, --rate-limit RATE_LIMIT
                        rate-limit in seconds between messages (default: 40)
  -s, --show-csv-users  also show all users from input CSV on terminal
  -D, --dry-run         list greeting and users but don't message
  -L, --log-to-file     log to file reddit-message.log
  -V, --verbose         increase verbosity from critical though error,
                        warning, info, and debug
  --version             show program's version number and exit
```
